{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "from lab3_tools import *\n",
    "from lab3_proto import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ah_0',\n",
       " 'ah_1',\n",
       " 'ah_2',\n",
       " 'ao_0',\n",
       " 'ao_1',\n",
       " 'ao_2',\n",
       " 'ay_0',\n",
       " 'ay_1',\n",
       " 'ay_2',\n",
       " 'eh_0',\n",
       " 'eh_1',\n",
       " 'eh_2',\n",
       " 'ey_0',\n",
       " 'ey_1',\n",
       " 'ey_2',\n",
       " 'f_0',\n",
       " 'f_1',\n",
       " 'f_2',\n",
       " 'ih_0',\n",
       " 'ih_1',\n",
       " 'ih_2',\n",
       " 'iy_0',\n",
       " 'iy_1',\n",
       " 'iy_2',\n",
       " 'k_0',\n",
       " 'k_1',\n",
       " 'k_2',\n",
       " 'n_0',\n",
       " 'n_1',\n",
       " 'n_2',\n",
       " 'ow_0',\n",
       " 'ow_1',\n",
       " 'ow_2',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 's_0',\n",
       " 's_1',\n",
       " 's_2',\n",
       " 'sil_0',\n",
       " 'sil_1',\n",
       " 'sil_2',\n",
       " 'sp_0',\n",
       " 't_0',\n",
       " 't_1',\n",
       " 't_2',\n",
       " 'th_0',\n",
       " 'th_1',\n",
       " 'th_2',\n",
       " 'uw_0',\n",
       " 'uw_1',\n",
       " 'uw_2',\n",
       " 'v_0',\n",
       " 'v_1',\n",
       " 'v_2',\n",
       " 'w_0',\n",
       " 'w_1',\n",
       " 'w_2',\n",
       " 'z_0',\n",
       " 'z_1',\n",
       " 'z_2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# phoneHMMs is a dictionary with 21 keys, each corresponding to a phonetic model\n",
    "phoneHMMs = np.load('../lab2/lab2_models_all.npz', allow_pickle=True)['phoneHMMs'].item()\n",
    "phones = sorted(phoneHMMs.keys())\n",
    "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "# A list of unique states for reference\n",
    "# Note that we model three segments for each phoneme\n",
    "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
    "stateList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio and compute liftered MFCC features\n",
    "sys.path.append('/Users/tim/Desktop/Speech/lab1')\n",
    "from lab1_proto import mfcc\n",
    "\n",
    "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "samples, samplingrate = loadAudio(filename)\n",
    "lmfcc = mfcc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['z', '4', '3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recover the sequence of digits (word level transcription) in the file\n",
    "wordTrans = list(path2info(filename)[2])\n",
    "wordTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sil',\n",
       " 'z',\n",
       " 'iy',\n",
       " 'r',\n",
       " 'ow',\n",
       " 'sp',\n",
       " 'f',\n",
       " 'ao',\n",
       " 'r',\n",
       " 'sp',\n",
       " 'th',\n",
       " 'r',\n",
       " 'iy',\n",
       " 'sp',\n",
       " 'sil']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prondict import prondict\n",
    "phoneTrans = words2phones(wordTrans, prondict)\n",
    "phoneTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/tim/Desktop/Speech/lab2')\n",
    "from lab2_proto import concatHMMs\n",
    "\n",
    "# Create a combined model for this specific utterance:\n",
    "utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sil_0',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_2',\n",
       " 'z_0',\n",
       " 'z_0',\n",
       " 'z_0',\n",
       " 'z_0',\n",
       " 'z_1',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_1',\n",
       " 'iy_2',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 'ow_0',\n",
       " 'ow_1',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'f_0',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_2',\n",
       " 'ao_0',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_1',\n",
       " 'th_1',\n",
       " 'th_1',\n",
       " 'th_2',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_1',\n",
       " 'iy_1',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lab2_tools import log_multivariate_normal_density_diag\n",
    "from lab2_proto import viterbi\n",
    "\n",
    "obsloglik = log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'], utteranceHMM['covars'])  \n",
    "log_startprob = np.log(utteranceHMM['startprob'][:-1])\n",
    "log_transmat = np.log(utteranceHMM['transmat'][:-1, :-1])\n",
    "vloglik, vpath = viterbi(obsloglik, log_startprob, log_transmat)\n",
    "\n",
    "stateList = [stateTrans[i] for i in vpath]\n",
    "stateList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
