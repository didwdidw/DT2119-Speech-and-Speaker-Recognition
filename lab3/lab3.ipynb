{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "from lab3_tools import *\n",
    "from lab3_proto import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ah_0',\n",
       " 'ah_1',\n",
       " 'ah_2',\n",
       " 'ao_0',\n",
       " 'ao_1',\n",
       " 'ao_2',\n",
       " 'ay_0',\n",
       " 'ay_1',\n",
       " 'ay_2',\n",
       " 'eh_0',\n",
       " 'eh_1',\n",
       " 'eh_2',\n",
       " 'ey_0',\n",
       " 'ey_1',\n",
       " 'ey_2',\n",
       " 'f_0',\n",
       " 'f_1',\n",
       " 'f_2',\n",
       " 'ih_0',\n",
       " 'ih_1',\n",
       " 'ih_2',\n",
       " 'iy_0',\n",
       " 'iy_1',\n",
       " 'iy_2',\n",
       " 'k_0',\n",
       " 'k_1',\n",
       " 'k_2',\n",
       " 'n_0',\n",
       " 'n_1',\n",
       " 'n_2',\n",
       " 'ow_0',\n",
       " 'ow_1',\n",
       " 'ow_2',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 's_0',\n",
       " 's_1',\n",
       " 's_2',\n",
       " 'sil_0',\n",
       " 'sil_1',\n",
       " 'sil_2',\n",
       " 'sp_0',\n",
       " 't_0',\n",
       " 't_1',\n",
       " 't_2',\n",
       " 'th_0',\n",
       " 'th_1',\n",
       " 'th_2',\n",
       " 'uw_0',\n",
       " 'uw_1',\n",
       " 'uw_2',\n",
       " 'v_0',\n",
       " 'v_1',\n",
       " 'v_2',\n",
       " 'w_0',\n",
       " 'w_1',\n",
       " 'w_2',\n",
       " 'z_0',\n",
       " 'z_1',\n",
       " 'z_2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# phoneHMMs is a dictionary with 21 keys, each corresponding to a phonetic model\n",
    "phoneHMMs = np.load('../lab2/lab2_models_all.npz', allow_pickle=True)['phoneHMMs'].item()\n",
    "phones = sorted(phoneHMMs.keys())\n",
    "nstates = {phone: phoneHMMs[phone]['means'].shape[0] for phone in phones}\n",
    "# A list of unique states for reference\n",
    "# Note that we model three segments for each phoneme\n",
    "stateList = [ph + '_' + str(id) for ph in phones for id in range(nstates[ph])]\n",
    "stateList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forced Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio and compute liftered MFCC features\n",
    "sys.path.append('/Users/tim/Desktop/Speech/lab1')\n",
    "from lab1_proto import mfcc\n",
    "\n",
    "filename = 'tidigits/disc_4.1.1/tidigits/train/man/nw/z43a.wav'\n",
    "samples, samplingrate = loadAudio(filename)\n",
    "lmfcc = mfcc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['z', '4', '3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recover the sequence of digits (word level transcription) in the file\n",
    "wordTrans = list(path2info(filename)[2])\n",
    "wordTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sil',\n",
       " 'z',\n",
       " 'iy',\n",
       " 'r',\n",
       " 'ow',\n",
       " 'sp',\n",
       " 'f',\n",
       " 'ao',\n",
       " 'r',\n",
       " 'sp',\n",
       " 'th',\n",
       " 'r',\n",
       " 'iy',\n",
       " 'sp',\n",
       " 'sil']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prondict import prondict\n",
    "phoneTrans = words2phones(wordTrans, prondict)\n",
    "phoneTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/tim/Desktop/Speech/lab2')\n",
    "from lab2_proto import concatHMMs\n",
    "\n",
    "# Create a combined model for this specific utterance:\n",
    "utteranceHMM = concatHMMs(phoneHMMs, phoneTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateTrans = [phone + '_' + str(stateid) for phone in phoneTrans for stateid in range(nstates[phone])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sil_0',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_1',\n",
       " 'sil_2',\n",
       " 'z_0',\n",
       " 'z_0',\n",
       " 'z_0',\n",
       " 'z_0',\n",
       " 'z_1',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'z_2',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_1',\n",
       " 'iy_2',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 'ow_0',\n",
       " 'ow_1',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'ow_2',\n",
       " 'f_0',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_1',\n",
       " 'f_2',\n",
       " 'ao_0',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_1',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'ao_2',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_0',\n",
       " 'th_1',\n",
       " 'th_1',\n",
       " 'th_1',\n",
       " 'th_2',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_0',\n",
       " 'r_1',\n",
       " 'r_2',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_0',\n",
       " 'iy_1',\n",
       " 'iy_1',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'iy_2',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0',\n",
       " 'sil_0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lab2_tools import log_multivariate_normal_density_diag\n",
    "from lab2_proto import viterbi\n",
    "\n",
    "# NxM array of emission(observation) log likelihoods, N frames, M states\n",
    "obsloglik = log_multivariate_normal_density_diag(lmfcc, utteranceHMM['means'], utteranceHMM['covars']) \n",
    "log_startprob = np.log(utteranceHMM['startprob'][:-1])\n",
    "log_transmat = np.log(utteranceHMM['transmat'][:-1, :-1])\n",
    "vloglik, vpath = viterbi(obsloglik, log_startprob, log_transmat)\n",
    "\n",
    "stateList = [stateTrans[i] for i in vpath]\n",
    "stateList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Last 2 dimensions of the array must be square",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m             lmfcc \u001b[38;5;241m=\u001b[39m mfcc(samples)\n\u001b[1;32m     10\u001b[0m             mspec \u001b[38;5;241m=\u001b[39m mspec(samples)\n\u001b[0;32m---> 11\u001b[0m             targets \u001b[38;5;241m=\u001b[39m \u001b[43mforcedAlignment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlmfcc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphoneHMMs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphoneTrans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m             traindata\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m: filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlmfcc\u001b[39m\u001b[38;5;124m'\u001b[39m: lmfcc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmspec\u001b[39m\u001b[38;5;124m'\u001b[39m: mspec, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m: targets})\n\u001b[1;32m     13\u001b[0m np\u001b[38;5;241m.\u001b[39msavez(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraindata.npz\u001b[39m\u001b[38;5;124m'\u001b[39m, traindata\u001b[38;5;241m=\u001b[39mtraindata)\n",
      "File \u001b[0;32m~/Desktop/Speech/lab3/lab3_proto.py:81\u001b[0m, in \u001b[0;36mforcedAlignment\u001b[0;34m(lmfcc, phoneHMMs, phoneTrans)\u001b[0m\n\u001b[1;32m     77\u001b[0m log_transmat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39marray(trans_mat))\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Compute log likelihood for each state using Gaussian mixture model\u001b[39;00m\n\u001b[1;32m     80\u001b[0m gmm \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(means), covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiag\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m---> 81\u001b[0m                       means_init\u001b[38;5;241m=\u001b[39mmeans, precisions_init\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcovars\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     82\u001b[0m gmm\u001b[38;5;241m.\u001b[39mmeans_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(means)\n\u001b[1;32m     83\u001b[0m gmm\u001b[38;5;241m.\u001b[39mcovariances_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(covars)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/linalg/linalg.py:533\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    531\u001b[0m a, wrap \u001b[38;5;241m=\u001b[39m _makearray(a)\n\u001b[1;32m    532\u001b[0m _assert_stacked_2d(a)\n\u001b[0;32m--> 533\u001b[0m \u001b[43m_assert_stacked_square\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n\u001b[1;32m    536\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/linalg/linalg.py:190\u001b[0m, in \u001b[0;36m_assert_stacked_square\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    188\u001b[0m m, n \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m!=\u001b[39m n:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast 2 dimensions of the array must be square\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
     ]
    }
   ],
   "source": [
    "from lab1_proto import mspec\n",
    "\n",
    "traindata = []\n",
    "for root, dirs, files in os.walk('tidigits/disc_4.1.1/tidigits/train'):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            filename = os.path.join(root, file)\n",
    "            samples, samplingrate = loadAudio(filename)\n",
    "            lmfcc = mfcc(samples)\n",
    "            mspec = mspec(samples)\n",
    "            targets = forcedAlignment(lmfcc, phoneHMMs, phoneTrans)\n",
    "            traindata.append({'filename': filename, 'lmfcc': lmfcc, 'mspec': mspec, 'targets': targets})\n",
    "np.savez('traindata.npz', traindata=traindata)\n",
    "\n",
    "testdata = []\n",
    "for root, dirs, files in os.walk('tidigits/disc_4.1.1/tidigits/train'):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            filename = os.path.join(root, file)\n",
    "            samples, samplingrate = loadAudio(filename)\n",
    "            lmfcc = mfcc(samples)\n",
    "            mspec = mspec(samples)\n",
    "            targets = forcedAlignment(lmfcc, phoneHMMs, phoneTrans)\n",
    "            testdata.append({'filename': filename, 'lmfcc': lmfcc, 'mspec': mspec, 'targets': targets})\n",
    "np.savez('testdata.npz', testdata=testdata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
